{"ast":null,"code":"\"use strict\";\n\nvar _toConsumableArray = require(\"@babel/runtime/helpers/toConsumableArray\");\n\nfunction _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.mergeContents = mergeContents;\nexports.removeContents = removeContents;\nexports.removeGeneratedContents = removeGeneratedContents;\nexports.createGeneratedHeaderComment = createGeneratedHeaderComment;\nexports.createHash = createHash;\n\nfunction _crypto() {\n  var data = _interopRequireDefault(require(\"crypto\"));\n\n  _crypto = function _crypto() {\n    return data;\n  };\n\n  return data;\n}\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\nfunction getGeneratedSectionIndexes(src, tag) {\n  var contents = src.split('\\n');\n  var start = contents.findIndex(function (line) {\n    return line.includes(\"@generated begin \" + tag);\n  });\n  var end = contents.findIndex(function (line) {\n    return line.includes(\"@generated end \" + tag);\n  });\n  return {\n    contents: contents,\n    start: start,\n    end: end\n  };\n}\n\nfunction mergeContents(_ref) {\n  var src = _ref.src,\n      newSrc = _ref.newSrc,\n      tag = _ref.tag,\n      anchor = _ref.anchor,\n      offset = _ref.offset,\n      comment = _ref.comment;\n  var header = createGeneratedHeaderComment(newSrc, tag, comment);\n\n  if (!src.includes(header)) {\n    var sanitizedTarget = removeGeneratedContents(src, tag);\n    return {\n      contents: addLines(sanitizedTarget !== null && sanitizedTarget !== void 0 ? sanitizedTarget : src, anchor, offset, [header].concat(_toConsumableArray(newSrc.split('\\n')), [comment + \" @generated end \" + tag])),\n      didMerge: true,\n      didClear: !!sanitizedTarget\n    };\n  }\n\n  return {\n    contents: src,\n    didClear: false,\n    didMerge: false\n  };\n}\n\nfunction removeContents(_ref2) {\n  var src = _ref2.src,\n      tag = _ref2.tag;\n  var sanitizedTarget = removeGeneratedContents(src, tag);\n  return {\n    contents: sanitizedTarget !== null && sanitizedTarget !== void 0 ? sanitizedTarget : src,\n    didMerge: false,\n    didClear: !!sanitizedTarget\n  };\n}\n\nfunction addLines(content, find, offset, toAdd) {\n  var lines = content.split('\\n');\n  var lineIndex = lines.findIndex(function (line) {\n    return line.match(find);\n  });\n\n  if (lineIndex < 0) {\n    var error = new Error(\"Failed to match \\\"\" + find + \"\\\" in contents:\\n\" + content);\n    error.code = 'ERR_NO_MATCH';\n    throw error;\n  }\n\n  for (var _iterator = _createForOfIteratorHelperLoose(toAdd), _step; !(_step = _iterator()).done;) {\n    var newLine = _step.value;\n    lines.splice(lineIndex + offset, 0, newLine);\n    lineIndex++;\n  }\n\n  return lines.join('\\n');\n}\n\nfunction removeGeneratedContents(src, tag) {\n  var _getGeneratedSectionI = getGeneratedSectionIndexes(src, tag),\n      contents = _getGeneratedSectionI.contents,\n      start = _getGeneratedSectionI.start,\n      end = _getGeneratedSectionI.end;\n\n  if (start > -1 && end > -1 && start < end) {\n    contents.splice(start, end - start + 1);\n    return contents.join('\\n');\n  }\n\n  return null;\n}\n\nfunction createGeneratedHeaderComment(contents, tag, comment) {\n  var hashKey = createHash(contents);\n  return comment + \" @generated begin \" + tag + \" - expo prebuild (DO NOT MODIFY) \" + hashKey;\n}\n\nfunction createHash(src) {\n  var hash = _crypto().default.createHash('sha1').update(src).digest('hex');\n\n  return \"sync-\" + hash;\n}","map":{"version":3,"sources":["../../src/utils/generateCode.ts"],"names":["contents","src","start","line","end","comment","header","createGeneratedHeaderComment","sanitizedTarget","removeGeneratedContents","addLines","newSrc","didMerge","didClear","tag","lines","content","lineIndex","error","find","getGeneratedSectionIndexes","hashKey","createHash","hash","crypto"],"mappings":";;;;;;;;;;;;;;;;;;;AAKA,SAAA,OAAA,GAAA;AAAA,MAAA,IAAA,GAAA,sBAAA,CAAA,OAAA,CAAA,QAAA,CAAA,CAAA;;AAAA,EAAA,OAAA,GAAA,mBAAA;AAAA,WAAA,IAAA;AAAA,GAAA;;AAAA,SAAA,IAAA;AAAA;;;;;;;;AAEA,SAAA,0BAAA,CAAA,GAAA,EAAA,GAAA,EAGsD;AACpD,MAAMA,QAAQ,GAAGC,GAAG,CAAHA,KAAAA,CAAjB,IAAiBA,CAAjB;AACA,MAAMC,KAAK,GAAGF,QAAQ,CAARA,SAAAA,CAAmBG,UAAAA,IAAI;AAAA,WAAIA,IAAI,CAAJA,QAAAA,uBAAzC,GAAyCA,CAAJ;AAAA,GAAvBH,CAAd;AACA,MAAMI,GAAG,GAAGJ,QAAQ,CAARA,SAAAA,CAAmBG,UAAAA,IAAI;AAAA,WAAIA,IAAI,CAAJA,QAAAA,qBAAvC,GAAuCA,CAAJ;AAAA,GAAvBH,CAAZ;AAEA,SAAO;AAAEA,IAAAA,QAAF,EAAEA,QAAF;AAAYE,IAAAA,KAAZ,EAAYA,KAAZ;AAAmBE,IAAAA,GAAAA,EAAAA;AAAnB,GAAP;AACD;;AAkBM,SAAA,aAAA,OAcU;AAAA,MAda,GAcb,QAda,GAcb;AAAA,MAda,MAcb,QAda,MAcb;AAAA,MAda,GAcb,QAda,GAcb;AAAA,MAda,MAcb,QAda,MAcb;AAAA,MAda,MAcb,QAda,MAcb;AAAA,MARfC,OAQe,QARfA,OAQe;AACf,MAAMC,MAAM,GAAGC,4BAA4B,CAAA,MAAA,EAAA,GAAA,EAA3C,OAA2C,CAA3C;;AACA,MAAI,CAACN,GAAG,CAAHA,QAAAA,CAAL,MAAKA,CAAL,EAA2B;AAEzB,QAAMO,eAAe,GAAGC,uBAAuB,CAAA,GAAA,EAA/C,GAA+C,CAA/C;AACA,WAAO;AACLT,MAAAA,QAAQ,EAAEU,QAAQ,CAACF,eAAD,KAAA,IAACA,IAAAA,eAAD,KAAA,KAAA,CAACA,GAAD,eAACA,GAAD,GAAA,EAAA,MAAA,EAAA,MAAA,GAAyC,MAAzC,4BAEbG,MAAM,CAANA,KAAAA,CAFsD,IAEtDA,CAFa,IAGbN,OAHa,wBADb,GACa,GADb;AAMLO,MAAAA,QAAQ,EANH,IAAA;AAOLC,MAAAA,QAAQ,EAAE,CAAC,CAACL;AAPP,KAAP;AASD;;AACD,SAAO;AAAER,IAAAA,QAAQ,EAAV,GAAA;AAAiBa,IAAAA,QAAQ,EAAzB,KAAA;AAAkCD,IAAAA,QAAQ,EAAE;AAA5C,GAAP;AACD;;AAEM,SAAA,cAAA,QAAkF;AAAA,MAA1D,GAA0D,SAA1D,GAA0D;AAAA,MAAnDE,GAAmD,SAAnDA,GAAmD;AAEvF,MAAMN,eAAe,GAAGC,uBAAuB,CAAA,GAAA,EAA/C,GAA+C,CAA/C;AACA,SAAO;AACLT,IAAAA,QAAQ,EAAEQ,eAAF,KAAA,IAAEA,IAAAA,eAAF,KAAA,KAAA,CAAEA,GAAF,eAAEA,GADL,GAAA;AAELI,IAAAA,QAAQ,EAFH,KAAA;AAGLC,IAAAA,QAAQ,EAAE,CAAC,CAACL;AAHP,GAAP;AAKD;;AAED,SAAA,QAAA,CAAA,OAAA,EAAA,IAAA,EAAA,MAAA,EAAA,KAAA,EAA2F;AACzF,MAAMO,KAAK,GAAGC,OAAO,CAAPA,KAAAA,CAAd,IAAcA,CAAd;AAEA,MAAIC,SAAS,GAAGF,KAAK,CAALA,SAAAA,CAAgBZ,UAAAA,IAAI;AAAA,WAAIA,IAAI,CAAJA,KAAAA,CAAxC,IAAwCA,CAAJ;AAAA,GAApBY,CAAhB;;AACA,MAAIE,SAAS,GAAb,CAAA,EAAmB;AACjB,QAAMC,KAAK,GAAG,IAAA,KAAA,wBAA8BC,IAA9B,yBADG,OACH,CAAd;AAEAD,IAAAA,KAAK,CAALA,IAAAA,GAAAA,cAAAA;AACA,UAAA,KAAA;AACD;;AACD,uDAAA,KAAA,wCAA6B;AAAA,QAA7B,OAA6B;AAC3BH,IAAAA,KAAK,CAALA,MAAAA,CAAaE,SAAS,GAAtBF,MAAAA,EAAAA,CAAAA,EAAAA,OAAAA;AACAE,IAAAA,SAAS;AACV;;AAED,SAAOF,KAAK,CAALA,IAAAA,CAAP,IAAOA,CAAP;AACD;;AAQM,SAAA,uBAAA,CAAA,GAAA,EAAA,GAAA,EAA0E;AAC/E,8BAAiCK,0BAA0B,CAAA,GAAA,EAA3D,GAA2D,CAA3D;AAAA,MAAM,QAAN,yBAAM,QAAN;AAAA,MAAM,KAAN,yBAAM,KAAN;AAAA,MAAyBhB,GAAzB,yBAAyBA,GAAzB;;AACA,MAAIF,KAAK,GAAG,CAARA,CAAAA,IAAcE,GAAG,GAAG,CAApBF,CAAAA,IAA0BA,KAAK,GAAnC,GAAA,EAA2C;AACzCF,IAAAA,QAAQ,CAARA,MAAAA,CAAAA,KAAAA,EAAuBI,GAAG,GAAHA,KAAAA,GADkB,CACzCJ;AAGA,WAAOA,QAAQ,CAARA,IAAAA,CAAP,IAAOA,CAAP;AACD;;AACD,SAAA,IAAA;AACD;;AAEM,SAAA,4BAAA,CAAA,QAAA,EAAA,GAAA,EAAA,OAAA,EAIG;AACR,MAAMqB,OAAO,GAAGC,UAAU,CADlB,QACkB,CAA1B;AAGA,SAAUjB,OAAV,0BAAsCS,GAAtC,yCAAA,OAAA;AACD;;AAEM,SAAA,UAAA,CAAA,GAAA,EAAyC;AAE9C,MAAMS,IAAI,GAAGC,OAAAA,GAAAA,OAAAA,CAAAA,UAAAA,CAAAA,MAAAA,EAAAA,MAAAA,CAAAA,GAAAA,EAAAA,MAAAA,CAAb,KAAaA,CAAb;;AACA,mBAAA,IAAA;AACD","sourcesContent":["/**\n * Get line indexes for the generated section of a file.\n *\n * @param src\n */\nimport crypto from 'crypto';\n\nfunction getGeneratedSectionIndexes(\n  src: string,\n  tag: string\n): { contents: string[]; start: number; end: number } {\n  const contents = src.split('\\n');\n  const start = contents.findIndex(line => line.includes(`@generated begin ${tag}`));\n  const end = contents.findIndex(line => line.includes(`@generated end ${tag}`));\n\n  return { contents, start, end };\n}\n\nexport type MergeResults = {\n  contents: string;\n  didClear: boolean;\n  didMerge: boolean;\n};\n\n/**\n * Merge the contents of two files together and add a generated header.\n *\n * @param src contents of the original file\n * @param newSrc new contents to merge into the original file\n * @param identifier used to update and remove merges\n * @param anchor regex to where the merge should begin\n * @param offset line offset to start merging at (<1 for behind the anchor)\n * @param comment comment style `//` or `#`\n */\nexport function mergeContents({\n  src,\n  newSrc,\n  tag,\n  anchor,\n  offset,\n  comment,\n}: {\n  src: string;\n  newSrc: string;\n  tag: string;\n  anchor: string | RegExp;\n  offset: number;\n  comment: string;\n}): MergeResults {\n  const header = createGeneratedHeaderComment(newSrc, tag, comment);\n  if (!src.includes(header)) {\n    // Ensure the old generated contents are removed.\n    const sanitizedTarget = removeGeneratedContents(src, tag);\n    return {\n      contents: addLines(sanitizedTarget ?? src, anchor, offset, [\n        header,\n        ...newSrc.split('\\n'),\n        `${comment} @generated end ${tag}`,\n      ]),\n      didMerge: true,\n      didClear: !!sanitizedTarget,\n    };\n  }\n  return { contents: src, didClear: false, didMerge: false };\n}\n\nexport function removeContents({ src, tag }: { src: string; tag: string }): MergeResults {\n  // Ensure the old generated contents are removed.\n  const sanitizedTarget = removeGeneratedContents(src, tag);\n  return {\n    contents: sanitizedTarget ?? src,\n    didMerge: false,\n    didClear: !!sanitizedTarget,\n  };\n}\n\nfunction addLines(content: string, find: string | RegExp, offset: number, toAdd: string[]) {\n  const lines = content.split('\\n');\n\n  let lineIndex = lines.findIndex(line => line.match(find));\n  if (lineIndex < 0) {\n    const error = new Error(`Failed to match \"${find}\" in contents:\\n${content}`);\n    // @ts-ignore\n    error.code = 'ERR_NO_MATCH';\n    throw error;\n  }\n  for (const newLine of toAdd) {\n    lines.splice(lineIndex + offset, 0, newLine);\n    lineIndex++;\n  }\n\n  return lines.join('\\n');\n}\n\n/**\n * Removes the generated section from a file, returns null when nothing can be removed.\n * This sways heavily towards not removing lines unless it's certain that modifications were not made manually.\n *\n * @param src\n */\nexport function removeGeneratedContents(src: string, tag: string): string | null {\n  const { contents, start, end } = getGeneratedSectionIndexes(src, tag);\n  if (start > -1 && end > -1 && start < end) {\n    contents.splice(start, end - start + 1);\n    // TODO: We could in theory check that the contents we're removing match the hash used in the header,\n    // this would ensure that we don't accidentally remove lines that someone added or removed from the generated section.\n    return contents.join('\\n');\n  }\n  return null;\n}\n\nexport function createGeneratedHeaderComment(\n  contents: string,\n  tag: string,\n  comment: string\n): string {\n  const hashKey = createHash(contents);\n\n  // Everything after the `${tag} ` is unversioned and can be freely modified without breaking changes.\n  return `${comment} @generated begin ${tag} - expo prebuild (DO NOT MODIFY) ${hashKey}`;\n}\n\nexport function createHash(src: string): string {\n  // this doesn't need to be secure, the shorter the better.\n  const hash = crypto.createHash('sha1').update(src).digest('hex');\n  return `sync-${hash}`;\n}\n"]},"metadata":{},"sourceType":"script"}